{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Analitica con Numpy, Pandas y ScikitLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pokeapi import Pokemon, render\n",
    "import plotly.offline as py\n",
    "from plotly import graph_objs as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "py.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pokemons = [ Pokemon.catch(i) for i in range(1, 500+1) ]\n",
    "for pokemon in pokemons:\n",
    "    pokemon[\"moves\"] = [ move[\"move\"][\"name\"] for move in pokemon[\"moves\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Numpy\n",
    "Numpy es..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "weights = [ pokemon[\"weight\"] for pokemon in pokemons ]\n",
    "weights = np.asarray(weights, dtype=np.float32)\n",
    "\n",
    "max_weight = np.max(weights)\n",
    "mas_pesado = np.argmax(weights)\n",
    "mas_pesado = pokemons[mas_pesado]\n",
    "\n",
    "print(\"Peso: {}\".format(max_weight))\n",
    "render(mas_pesado)\n",
    "\n",
    "\n",
    "min_weight = np.min(weights)\n",
    "mas_liviano = np.argmin(weights)\n",
    "mas_liviano = pokemons[mas_liviano]\n",
    "\n",
    "print(\"Peso: {}\".format(min_weight))\n",
    "render(mas_liviano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#promedio\n",
    "peso_promedio = np.average(weights)\n",
    "print(\"Peso promedio: {}\".format(peso_promedio))\n",
    "\n",
    "error_cuadratico_promedio = (weights - peso_promedio) ** 2\n",
    "cercano_al_promedio = np.argmin(error_cuadratico_promedio)\n",
    "cercano_al_promedio = pokemons[cercano_al_promedio]\n",
    "\n",
    "print(\"Peso: {}\".format(cercano_al_promedio[\"weight\"]))\n",
    "render(cercano_al_promedio)\n",
    "\n",
    "\n",
    "#media\n",
    "peso_medio = np.median(weights)\n",
    "print(\"Peso medio: {}\".format(peso_medio))\n",
    "\n",
    "error_cuadratico_medio = (weights - peso_medio) ** 2\n",
    "cercano_al_medio = np.argmin(error_cuadratico_medio)\n",
    "cercano_al_medio = pokemons[cercano_al_medio]\n",
    "\n",
    "print(\"Peso: {}\".format(cercano_al_medio[\"weight\"]))\n",
    "render(cercano_al_medio)\n",
    "\n",
    "\n",
    "#visualizar datos\n",
    "histogram = go.Histogram(\n",
    "    x = weights,\n",
    "    name = \"weights\"\n",
    ")\n",
    "\n",
    "data = [histogram]\n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "poke_df = pd.DataFrame(pokemons)\n",
    "poke_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_weight = poke_df.weight.max()\n",
    "mas_pesado = poke_df.weight.argmax()\n",
    "mas_pesado = pokemons[mas_pesado]\n",
    "\n",
    "print(\"Peso: {}\".format(max_weight))\n",
    "render(mas_pesado)\n",
    "\n",
    "\n",
    "min_weight = poke_df.weight.min()\n",
    "mas_liviano = poke_df.weight.argmin()\n",
    "mas_liviano = pokemons[mas_liviano]\n",
    "\n",
    "print(\"Peso: {}\".format(min_weight))\n",
    "render(mas_liviano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#promedio\n",
    "peso_promedio = poke_df.weight.mean()\n",
    "print(\"Peso promedio: {}\".format(peso_promedio))\n",
    "\n",
    "error_cuadratico_promedio = (poke_df.weight - peso_promedio) ** 2\n",
    "cercano_al_promedio = error_cuadratico_promedio.argmin()\n",
    "cercano_al_promedio = pokemons[cercano_al_promedio]\n",
    "\n",
    "print(\"Peso: {}\".format(cercano_al_promedio[\"weight\"]))\n",
    "render(cercano_al_promedio)\n",
    "\n",
    "\n",
    "#media\n",
    "peso_medio = poke_df.weight.median()\n",
    "print(\"Peso medio: {}\".format(peso_medio))\n",
    "\n",
    "error_cuadratico_medio = (poke_df.weight - peso_medio) ** 2\n",
    "cercano_al_medio = error_cuadratico_medio.argmin()\n",
    "cercano_al_medio = pokemons[cercano_al_medio]\n",
    "\n",
    "print(\"Peso: {}\".format(cercano_al_medio[\"weight\"]))\n",
    "render(cercano_al_medio)\n",
    "\n",
    "\n",
    "#visualizar datos\n",
    "histogram = go.Histogram(\n",
    "    x = poke_df.weight,\n",
    "    name = \"weights\"\n",
    ")\n",
    "\n",
    "data = [histogram]\n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### regression lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.io.parsers.read_csv(\"data/ex1data1.txt\", header=None).as_matrix()\n",
    "\n",
    "scatter_data = go.Scatter(\n",
    "    x = data[:, 0],\n",
    "    y = data[:, 1],\n",
    "    mode = \"markers\",\n",
    "    name = \"data\"\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Poblacion vs Ventas',\n",
    "    yaxis = dict(\n",
    "        zeroline = False,\n",
    "        title = \"Ventas\"\n",
    "    ),\n",
    "    xaxis = dict(\n",
    "        zeroline = False,\n",
    "        title = \"Poblacion\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = dict(data=[scatter_data], layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(data[:, :1], data[:, 1])\n",
    "\n",
    "line_x = np.asarray([[5], [23]])\n",
    "line_y = model.predict(line_x)\n",
    "\n",
    "linear_reg_line = go.Scatter(\n",
    "    x = line_x[:, 0],\n",
    "    y = line_y,\n",
    "    mode = \"lines\",\n",
    "    name = \"model\"\n",
    ")\n",
    "\n",
    "fig = dict(data=[scatter_data, linear_reg_line], layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### regresion lineal multivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"data/ex1data2.txt\", header=None)\n",
    "\n",
    "scatter_data2 = go.Scatter3d(\n",
    "    x = data2[0],\n",
    "    y = data2[1],\n",
    "    z = data2[2],\n",
    "    mode = \"markers\",\n",
    "    name = \"data\"\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Poblacion vs Ventas',\n",
    "    yaxis = dict(\n",
    "        zeroline = False,\n",
    "        title = \"Ventas\"\n",
    "    ),\n",
    "    xaxis = dict(\n",
    "        zeroline = False,\n",
    "        title = \"Poblacion\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = dict(data=[scatter_data2], layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model2 = LinearRegression()\n",
    "model2.fit(data2[[0, 1]], data2[2])\n",
    "\n",
    "x2 = np.arange(500, 4500, 50)\n",
    "y2 = np.arange(0, 5, 0.1)\n",
    "xx, yy = np.meshgrid(x2, y2)\n",
    "\n",
    "features = np.hstack((np.expand_dims(xx.flatten(), 1), np.expand_dims(yy.flatten(), 1)))\n",
    "zz = model2.predict(features)\n",
    "zz = zz.reshape(xx.shape)\n",
    "\n",
    "linear_reg_line2 = go.Surface(\n",
    "    x = xx,\n",
    "    y = yy,\n",
    "    z = zz,\n",
    "    name = \"model\"\n",
    ")\n",
    "\n",
    "fig = dict(data=[scatter_data2, linear_reg_line2])\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### regresion polinomica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data3 = pd.read_csv(\"data/ex2data1.txt\", header=None, names=[\"exam1\", \"exam2\", \"passed\"])\n",
    "\n",
    "scatter_0 = go.Scatter(\n",
    "    x = data3[data3.passed == 0].exam1,\n",
    "    y = data3[data3.passed == 0].exam2,\n",
    "    mode = \"markers\",\n",
    "    name = \"failed\",\n",
    "    marker = dict(\n",
    "        color = \"red\"\n",
    "    )\n",
    ")\n",
    "\n",
    "scatter_1 = go.Scatter(\n",
    "    x = data3[data3.passed == 1].exam1,\n",
    "    y = data3[data3.passed == 1].exam2,\n",
    "    mode = \"markers\",\n",
    "    name = \"passed\",\n",
    "    marker = dict(\n",
    "        color = \"blue\"\n",
    "    )\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Poblacion vs Ventas',\n",
    "    yaxis = dict(\n",
    "        zeroline = False,\n",
    "        title = \"Ventas\"\n",
    "    ),\n",
    "    xaxis = dict(\n",
    "        zeroline = False,\n",
    "        title = \"Poblacion\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = dict(data=[scatter_0, scatter_1], layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "features = data3[[\"exam1\", \"exam2\"]]\n",
    "labels = data3[\"passed\"]\n",
    "\n",
    "model3 = LogisticRegression()\n",
    "model3.fit(features, labels)\n",
    "\n",
    "\n",
    "x3, y3 = np.meshgrid(np.arange(30, 101, 0.5), np.arange(30, 101, 0.5))\n",
    "flat_mesh3 = np.hstack((np.expand_dims(x3.flatten(), 1), np.expand_dims(y3.flatten(), 1)))\n",
    "z3 = model3.predict(flat_mesh3)\n",
    "z3 = z3.reshape(x3.shape)\n",
    "\n",
    "frontera3 = go.Heatmap(\n",
    "    x = x3[0, :],\n",
    "    y = y3[:, 0],\n",
    "    z = -z3,\n",
    "    name = \"model\"\n",
    ")\n",
    "\n",
    "fig = dict(data=[frontera3, scatter_0, scatter_1])\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "features = data3[[\"exam1\", \"exam2\"]]\n",
    "labels = data3[\"passed\"]\n",
    "\n",
    "model3 = GaussianNB()\n",
    "model3.fit(features, labels)\n",
    "\n",
    "x3, y3 = np.meshgrid(np.arange(30, 101, 0.5), np.arange(30, 101, 0.5))\n",
    "flat_mesh3 = np.hstack((np.expand_dims(x3.flatten(), 1), np.expand_dims(y3.flatten(), 1)))\n",
    "z3 = model3.predict(flat_mesh3)\n",
    "z3 = z3.reshape(x3.shape)\n",
    "\n",
    "frontera3 = go.Heatmap(\n",
    "    x = x3[0, :],\n",
    "    y = y3[:, 0],\n",
    "    z = -z3,\n",
    "    name = \"model\"\n",
    ")\n",
    "\n",
    "fig = dict(data=[frontera3, scatter_0, scatter_1])\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "features = data3[[\"exam1\", \"exam2\"]]\n",
    "labels = data3[\"passed\"]\n",
    "\n",
    "model3 = RandomForestClassifier(min_samples_split=10, n_estimators=50)\n",
    "model3.fit(features, labels)\n",
    "\n",
    "x3, y3 = np.meshgrid(np.arange(30, 101, 0.5), np.arange(30, 101, 0.5))\n",
    "flat_mesh3 = np.hstack((np.expand_dims(x3.flatten(), 1), np.expand_dims(y3.flatten(), 1)))\n",
    "z3 = model3.predict(flat_mesh3)\n",
    "z3 = z3.reshape(x3.shape)\n",
    "\n",
    "frontera3 = go.Heatmap(\n",
    "    x = x3[0, :],\n",
    "    y = y3[:, 0],\n",
    "    z = -z3,\n",
    "    name = \"model\"\n",
    ")\n",
    "\n",
    "fig = dict(data=[frontera3, scatter_0, scatter_1])\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "features = data3[[\"exam1\", \"exam2\"]]\n",
    "labels = data3[\"passed\"]\n",
    "\n",
    "model3 = SVC(gamma=0.005, C=100)\n",
    "model3.fit(features, labels)\n",
    "\n",
    "x3, y3 = np.meshgrid(np.arange(30, 101, 0.5), np.arange(30, 101, 0.5))\n",
    "flat_mesh3 = np.hstack((np.expand_dims(x3.flatten(), 1), np.expand_dims(y3.flatten(), 1)))\n",
    "z3 = model3.predict(flat_mesh3)\n",
    "z3 = z3.reshape(x3.shape)\n",
    "\n",
    "frontera3 = go.Heatmap(\n",
    "    x = x3[0, :],\n",
    "    y = y3[:, 0],\n",
    "    z = -z3,\n",
    "    name = \"model\"\n",
    ")\n",
    "\n",
    "fig = dict(data=[frontera3, scatter_0, scatter_1])\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### regression logistica polinomica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "features = data3[[\"exam1\", \"exam2\"]]\n",
    "labels = data3[\"passed\"]\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "features = poly.fit_transform(features)\n",
    "\n",
    "model3 = LogisticRegression()\n",
    "model3.fit(features, labels)\n",
    "\n",
    "\n",
    "x3, y3 = np.meshgrid(np.arange(30, 101, 0.5), np.arange(30, 101, 0.5))\n",
    "flat_mesh3 = np.hstack((np.expand_dims(x3.flatten(), 1), np.expand_dims(y3.flatten(), 1)))\n",
    "flat_mesh3 = poly.fit_transform(flat_mesh3)\n",
    "z3 = model3.predict(flat_mesh3)\n",
    "z3 = z3.reshape(x3.shape)\n",
    "\n",
    "frontera3 = go.Heatmap(\n",
    "    x = x3[0, :],\n",
    "    y = y3[:, 0],\n",
    "    z = -z3,\n",
    "    name = \"model\"\n",
    ")\n",
    "\n",
    "fig = dict(data=[frontera3, scatter_0, scatter_1])\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Reduccion de Dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "houses = np.loadtxt('data/house16H.dat', comments='@', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Esta base de datos fue diseñada sobre la base de los datos proporcionados por la Oficina del Censo de los Estados Unidos http://www.census.gov. Los datos se recolectaron como parte del censo de 1990 en los Estados Unidos. Estos son en su mayoría recuentos acumulados en diferentes niveles de la encuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "houses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "\n",
    "houses_compact = PCA(n_components=3).fit_transform(houses)\n",
    "houses_compact = houses_compact[random.sample(range(houses_compact.shape[0]), 1000)]\n",
    "\n",
    "scatter_houses = dict(\n",
    "    mode = \"markers\",\n",
    "    type = \"scatter3d\",\n",
    "    marker = dict( size=2 ),\n",
    "    x = houses_compact[:, 0], y = houses_compact[:, 1], z = houses_compact[:, 2]\n",
    ")\n",
    "cluster_houses = dict(\n",
    "    alphahull = 7,\n",
    "    opacity = 0.1,\n",
    "    type = \"mesh3d\",    \n",
    "    x = houses_compact[:, 0], y = houses_compact[:, 1], z = houses_compact[:, 2]\n",
    ")\n",
    "\n",
    "layout = dict(\n",
    "    title = '3d point clustering',\n",
    "    scene = dict(\n",
    "        xaxis = dict( zeroline=False ),\n",
    "        yaxis = dict( zeroline=False ),\n",
    "        zaxis = dict( zeroline=False ),\n",
    "    ),\n",
    "    height = 600, width = 800\n",
    ")\n",
    "fig = dict( data= [cluster_houses, scatter_houses], layout=layout )\n",
    "# Use py.iplot() for IPython notebook\n",
    "py.iplot(fig, filename='Iris Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "houses_compact"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
